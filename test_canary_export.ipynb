{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4dc352c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tassilo-holtzwart/Projects/Sotalis/stt_export/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[NeMo W 2026-01-08 00:21:20 nemo_logging:405] Megatron num_microbatches_calculator not found, using Apex version.\n",
      "OneLogger: Setting error_handling_strategy to DISABLE_QUIETLY_AND_REPORT_METRIC_ERROR for rank (rank=0) with OneLogger disabled. To override: explicitly set error_handling_strategy parameter.\n",
      "No exporters were provided. This means that no telemetry data will be collected.\n"
     ]
    }
   ],
   "source": [
    "from nemo.collections.asr.models.aed_multitask_models import EncDecMultiTaskModel, MultiTaskTranscriptionConfig\n",
    "import librosa\n",
    "from IPython.display import Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0c1bff8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2026-01-08 00:21:22 nemo_logging:393] _setup_tokenizer: detected an aggregate tokenizer\n",
      "[NeMo I 2026-01-08 00:21:22 nemo_logging:393] Tokenizer SentencePieceTokenizer initialized with 1152 tokens\n",
      "[NeMo I 2026-01-08 00:21:22 nemo_logging:393] Tokenizer SentencePieceTokenizer initialized with 1024 tokens\n",
      "[NeMo I 2026-01-08 00:21:22 nemo_logging:393] Tokenizer SentencePieceTokenizer initialized with 1024 tokens\n",
      "[NeMo I 2026-01-08 00:21:22 nemo_logging:393] Tokenizer SentencePieceTokenizer initialized with 1024 tokens\n",
      "[NeMo I 2026-01-08 00:21:22 nemo_logging:393] Tokenizer SentencePieceTokenizer initialized with 1024 tokens\n",
      "[NeMo I 2026-01-08 00:21:22 nemo_logging:393] Aggregate vocab size: 5248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 00:21:22 nemo_logging:405] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
      "    Train config : \n",
      "    use_lhotse: true\n",
      "    input_cfg: null\n",
      "    tarred_audio_filepaths: null\n",
      "    manifest_filepath: null\n",
      "    sample_rate: 16000\n",
      "    shuffle: true\n",
      "    num_workers: 8\n",
      "    pin_memory: true\n",
      "    prompt_format: canary2\n",
      "    max_tps: 25\n",
      "    max_duration: 40.0\n",
      "    text_field: answer\n",
      "    lang_field: target_lang\n",
      "    use_bucketing: true\n",
      "    bucket_duration_bins:\n",
      "    - - 3.56\n",
      "      - 30\n",
      "    - - 3.56\n",
      "      - 77\n",
      "    - - 4.608\n",
      "      - 38\n",
      "    - - 4.608\n",
      "      - 88\n",
      "    - - 5.48\n",
      "      - 49\n",
      "    - - 5.48\n",
      "      - 106\n",
      "    - - 6.05\n",
      "      - 52\n",
      "    - - 6.05\n",
      "      - 109\n",
      "    - - 6.85\n",
      "      - 54\n",
      "    - - 6.85\n",
      "      - 124\n",
      "    - - 7.914\n",
      "      - 59\n",
      "    - - 7.914\n",
      "      - 137\n",
      "    - - 8.52\n",
      "      - 67\n",
      "    - - 8.52\n",
      "      - 158\n",
      "    - - 9.51\n",
      "      - 67\n",
      "    - - 9.51\n",
      "      - 153\n",
      "    - - 10.29\n",
      "      - 78\n",
      "    - - 10.29\n",
      "      - 202\n",
      "    - - 10.89\n",
      "      - 88\n",
      "    - - 10.89\n",
      "      - 197\n",
      "    - - 11.45\n",
      "      - 92\n",
      "    - - 11.45\n",
      "      - 217\n",
      "    - - 12.1\n",
      "      - 98\n",
      "    - - 12.1\n",
      "      - 222\n",
      "    - - 12.69\n",
      "      - 123\n",
      "    - - 12.69\n",
      "      - 257\n",
      "    - - 13.09\n",
      "      - 133\n",
      "    - - 13.09\n",
      "      - 245\n",
      "    - - 13.57\n",
      "      - 104\n",
      "    - - 13.57\n",
      "      - 225\n",
      "    - - 14.02\n",
      "      - 108\n",
      "    - - 14.02\n",
      "      - 238\n",
      "    - - 14.53\n",
      "      - 117\n",
      "    - - 14.53\n",
      "      - 235\n",
      "    - - 15.08\n",
      "      - 135\n",
      "    - - 15.08\n",
      "      - 253\n",
      "    - - 15.53\n",
      "      - 130\n",
      "    - - 15.53\n",
      "      - 273\n",
      "    - - 15.945\n",
      "      - 123\n",
      "    - - 15.945\n",
      "      - 270\n",
      "    - - 16.4\n",
      "      - 126\n",
      "    - - 16.4\n",
      "      - 284\n",
      "    - - 16.9\n",
      "      - 126\n",
      "    - - 16.9\n",
      "      - 294\n",
      "    - - 17.44\n",
      "      - 127\n",
      "    - - 17.44\n",
      "      - 296\n",
      "    - - 17.96\n",
      "      - 131\n",
      "    - - 17.96\n",
      "      - 290\n",
      "    - - 18.41\n",
      "      - 133\n",
      "    - - 18.41\n",
      "      - 308\n",
      "    - - 18.91\n",
      "      - 137\n",
      "    - - 18.91\n",
      "      - 320\n",
      "    - - 19.42\n",
      "      - 135\n",
      "    - - 19.42\n",
      "      - 313\n",
      "    - - 20.0\n",
      "      - 138\n",
      "    - - 20.0\n",
      "      - 311\n",
      "    - - 34.547\n",
      "      - 195\n",
      "    - - 34.547\n",
      "      - 434\n",
      "    - - 40.0\n",
      "      - 263\n",
      "    - - 40.0\n",
      "      - 381\n",
      "    bucket_batch_size:\n",
      "    - 1044\n",
      "    - 835\n",
      "    - 786\n",
      "    - 662\n",
      "    - 662\n",
      "    - 558\n",
      "    - 594\n",
      "    - 501\n",
      "    - 534\n",
      "    - 450\n",
      "    - 465\n",
      "    - 391\n",
      "    - 417\n",
      "    - 342\n",
      "    - 378\n",
      "    - 318\n",
      "    - 340\n",
      "    - 271\n",
      "    - 322\n",
      "    - 258\n",
      "    - 295\n",
      "    - 248\n",
      "    - 284\n",
      "    - 234\n",
      "    - 250\n",
      "    - 210\n",
      "    - 250\n",
      "    - 210\n",
      "    - 250\n",
      "    - 210\n",
      "    - 241\n",
      "    - 203\n",
      "    - 232\n",
      "    - 196\n",
      "    - 216\n",
      "    - 187\n",
      "    - 207\n",
      "    - 174\n",
      "    - 207\n",
      "    - 174\n",
      "    - 199\n",
      "    - 163\n",
      "    - 194\n",
      "    - 163\n",
      "    - 188\n",
      "    - 158\n",
      "    - 186\n",
      "    - 156\n",
      "    - 172\n",
      "    - 145\n",
      "    - 173\n",
      "    - 142\n",
      "    - 167\n",
      "    - 140\n",
      "    - 160\n",
      "    - 135\n",
      "    - 86\n",
      "    - 74\n",
      "    - 70\n",
      "    - 64\n",
      "    bucket_buffer_size: 40000\n",
      "    shuffle_buffer_size: 10000\n",
      "    concurrent_bucketing: false\n",
      "    augmentor: null\n",
      "    \n",
      "[NeMo W 2026-01-08 00:21:22 nemo_logging:405] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
      "    Validation config : \n",
      "    use_lhotse: true\n",
      "    prompt_format: canary2\n",
      "    manifest_filepath: /data/ASR/librispeech/test_other.json\n",
      "    sample_rate: 16000\n",
      "    batch_size: 32\n",
      "    shuffle: false\n",
      "    num_workers: 2\n",
      "    pin_memory: true\n",
      "    text_field: answer\n",
      "    lang_field: target_lang\n",
      "    tarred_audio_filepaths: null\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2026-01-08 00:21:22 nemo_logging:393] PADDING: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error getting class at nemo.collections.asr.modules.transformer.get_nemo_transformer: Located non-class of type 'function' while loading 'nemo.collections.asr.modules.transformer.get_nemo_transformer'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2026-01-08 00:21:24 nemo_logging:393] Model EncDecMultiTaskModel was successfully restored from /home/tassilo-holtzwart/.cache/huggingface/hub/models--nvidia--canary-180m-flash/snapshots/b12ab418510d093e83890178fd0e8b0d0f7918a6/canary-180m-flash.nemo.\n"
     ]
    }
   ],
   "source": [
    "canary:EncDecMultiTaskModel = EncDecMultiTaskModel.from_pretrained(model_name=\"nvidia/canary-180m-flash\", map_location=\"cpu\").eval() # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "572ef911",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "audio_paths = [os.path.join(root, file)\n",
    "               for root, _, files in os.walk(\"audios\")\n",
    "               for file in files if file.endswith(('.wav', '.mp3'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "50bedde6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "audio_batch = [torch.tensor(librosa.load(ap, sr= 16000)[0]) for ap in audio_paths]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d9059f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_lengths = [len(audio) for audio in audio_batch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf6aab32",
   "metadata": {},
   "outputs": [],
   "source": [
    "audios = torch.nn.utils.rnn.pad_sequence(audio_batch, batch_first=True)\n",
    "lengths = torch.tensor(audio_lengths, dtype=torch.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aba7cc32",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2026-01-08 00:21:25 nemo_logging:405] Chunking is disabled. Please pass a single audio file or set batch_size to 1\n",
      "[NeMo W 2026-01-08 00:21:25 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: trim_silence,enable_chunking\n",
      "[NeMo W 2026-01-08 00:21:25 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)\n",
      "Transcribing: 2it [00:05,  2.63s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Hypothesis(score=0.0, y_sequence=tensor([2215, 2359, 2505, 2218, 2252, 2212, 2529, 2178, 2609, 2728, 2390, 2212,\n",
       "         2184, 2267, 2255, 2204, 2474, 2178, 2243, 2200, 2218, 2403, 2205, 2351,\n",
       "         2440, 2184, 2459, 2866, 3062, 2327, 2611, 2197, 2955, 2400, 3054, 2218,\n",
       "         2389, 2247, 2285, 2242, 2352, 2529, 2177, 2335, 2270, 2348, 2194, 2474,\n",
       "         2763, 2228, 2299, 2290, 3075, 2223, 3051, 2412, 2213]), text=' Sadik , der in ihren Herzen wie in seinem eigenen las , hatte immer seine Freude daran gehabt , dem Wachstum ihrer gegenseitigen Neigung zuzusehen .', dec_out=None, dec_state=None, timestamp=[], alignments=None, frame_confidence=None, token_confidence=None, word_confidence=None, length=0, y=None, lm_state=None, lm_scores=None, ngram_lm_state=None, tokens=None, last_token=None, token_duration=None, last_frame=None),\n",
       " Hypothesis(score=0.0, y_sequence=tensor([2284, 2267, 2275, 2222, 2296, 2308, 2291, 2629, 2178, 2232, 2256, 2267,\n",
       "         2965, 2194, 2262, 2213, 2569, 2247, 2407, 2239, 3051, 2257, 3052, 3075,\n",
       "         2681, 3057, 2687, 3079, 2205, 2351, 2519, 3069, 2237, 2281]), text=' Kein Falsch ist an ihnen und kein Flitter . Ein Wort eine Enziansblüte im Gebirge', dec_out=None, dec_state=None, timestamp=[], alignments=None, frame_confidence=None, token_confidence=None, word_confidence=None, length=0, y=None, lm_state=None, lm_scores=None, ngram_lm_state=None, tokens=None, last_token=None, token_duration=None, last_frame=None),\n",
       " Hypothesis(score=0.0, y_sequence=tensor([2337, 2301, 3075, 2228, 2473, 2604, 2374, 2284, 2193, 2263, 3060, 2275,\n",
       "         2177, 3060, 2181, 2307, 2963, 3072, 2177, 2218, 2303, 2287, 2184, 2267,\n",
       "         2287, 2242, 2188, 2250, 2385, 2239, 2256, 2868, 2188, 2250, 2385, 2268,\n",
       "         2219, 2198, 2205, 2329, 3092, 2446, 2251, 2289, 2205, 2213]), text=' Vierzig Jahre war Konrad Ferdinand Meyer , als er sein erstes Buch ein kleines Buch Gedichte veröffentlichte .', dec_out=None, dec_state=None, timestamp=[], alignments=None, frame_confidence=None, token_confidence=None, word_confidence=None, length=0, y=None, lm_state=None, lm_scores=None, ngram_lm_state=None, tokens=None, last_token=None, token_duration=None, last_frame=None),\n",
       " Hypothesis(score=0.0, y_sequence=tensor([2241, 2260, 3035, 2539, 2289, 2184, 2362, 2218, 2256, 2267, 2178, 2229,\n",
       "         2841, 2907, 2411, 2281, 2282, 2290, 2256, 2387, 2178, 2303, 2241, 2316,\n",
       "         2196, 2238, 2213]), text=' die so glücklich sind , keinen anderen Gesetzgeber zu kennen als die Natur .', dec_out=None, dec_state=None, timestamp=[], alignments=None, frame_confidence=None, token_confidence=None, word_confidence=None, length=0, y=None, lm_state=None, lm_scores=None, ngram_lm_state=None, tokens=None, last_token=None, token_duration=None, last_frame=None),\n",
       " Hypothesis(score=0.0, y_sequence=tensor([2304, 2185, 2434, 2272, 2338, 2195, 2285, 2178, 2218, 2185, 2387, 2287,\n",
       "         2529, 2177, 2594, 3053, 2211, 2320, 2183, 2610, 2360, 2184, 2198, 2202,\n",
       "         3082, 2452, 3051, 2213, 2447, 2942, 2327, 2353, 2351, 2440, 2260, 2291,\n",
       "         2711, 2281, 2412, 2185, 2189, 2425, 2218, 2259, 3057, 2287, 2538, 2257,\n",
       "         2187, 3051, 2501, 2482, 2244, 3058, 2437, 2205, 2213]), text=' was wollten wir machen , wenn er ihrer zwei oder drei mit sich nähme . Er würde es immer so anzugehen wissen , dass er am Ende Recht behielte .', dec_out=None, dec_state=None, timestamp=[], alignments=None, frame_confidence=None, token_confidence=None, word_confidence=None, length=0, y=None, lm_state=None, lm_scores=None, ngram_lm_state=None, tokens=None, last_token=None, token_duration=None, last_frame=None),\n",
       " Hypothesis(score=0.0, y_sequence=tensor([2930, 2308, 2360, 2258, 2189, 2262, 2319, 2656, 2188, 2262, 2693, 2431,\n",
       "         2412, 3105, 2927, 2335, 2361, 2353, 2675, 3105, 2961, 2308, 2287, 3105]), text=' Was ist mit Mister Rochester geschehen? Wie geht es ihm? Wo ist er?', dec_out=None, dec_state=None, timestamp=[], alignments=None, frame_confidence=None, token_confidence=None, word_confidence=None, length=0, y=None, lm_state=None, lm_scores=None, ngram_lm_state=None, tokens=None, last_token=None, token_duration=None, last_frame=None),\n",
       " Hypothesis(score=0.0, y_sequence=tensor([2234, 2298, 2202, 3082, 2442, 2205, 2287, 2184, 2198, 2389, 2275, 3051,\n",
       "         3062, 2177, 3070, 2608, 2374, 2239, 2190, 2462, 2188, 2397, 2539, 2600,\n",
       "         2787, 3068, 2190, 2301, 2442, 2290, 3033, 2197, 2270, 3068, 2259, 2256,\n",
       "         2298, 2314, 2220, 2369, 2178, 2329, 3057, 2198, 2406, 3070]), text=' Dann näherte er sich dem Feuer. Es war ein hartes Stück Arbeit, hierher zu gelangen, das kann ich Ihnen versichern.', dec_out=None, dec_state=None, timestamp=[], alignments=None, frame_confidence=None, token_confidence=None, word_confidence=None, length=0, y=None, lm_state=None, lm_scores=None, ngram_lm_state=None, tokens=None, last_token=None, token_duration=None, last_frame=None),\n",
       " Hypothesis(score=0.0, y_sequence=tensor([2481, 2390, 2320, 2352, 2521, 2242, 2307, 2239, 3051, 2293, 2547, 2213,\n",
       "         2430, 2331, 2276, 2349, 3061, 2625, 2182, 2482, 2391, 3061, 3082, 2281]), text=' ja wiederum entstand eine Pause . Die Uhr schlug acht Schläge', dec_out=None, dec_state=None, timestamp=[], alignments=None, frame_confidence=None, token_confidence=None, word_confidence=None, length=0, y=None, lm_state=None, lm_scores=None, ngram_lm_state=None, tokens=None, last_token=None, token_duration=None, last_frame=None)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "canary.transcribe(audio_paths, source_lang='de', target_lang='de')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6af10cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "trcfg = MultiTaskTranscriptionConfig(\n",
    "            batch_size=4,\n",
    "            return_hypotheses=False,\n",
    "            num_workers=0,\n",
    "            channel_selector=None,\n",
    "            augmentor=None,\n",
    "            verbose=True,\n",
    "            prompt={\n",
    "                \"source_lang\": \"de\",\n",
    "                \"target_lang\": \"de\"\n",
    "            },\n",
    "            timestamps=False,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "afb1c793",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "prompt = [{'role': 'user', 'slots': {'source_lang': 'de', 'target_lang': 'de'}}]\n",
    "default_turns = canary.prompt.get_default_dialog_slots()\n",
    "turns = prompt.copy()  # shallow copy #1: don't override the config\n",
    "for turn in turns:\n",
    "    role = turn[\"role\"]\n",
    "    # Check if we have defaults for this role.\n",
    "    # There shouldn't be more than a single turn for a given role, but if there are,\n",
    "    # we'll emit a warning.\n",
    "    if default_turns_for_role := [t for t in default_turns if t[\"role\"] == role]:\n",
    "        if len(default_turns_for_role) > 1:\n",
    "            warnings.warn(\n",
    "                f\"More than one default turn detected for {role=}. \"\n",
    "                f\"We'll be using default slot values for the first turn of {role=} only.\"\n",
    "            )\n",
    "        default_slots = default_turns_for_role[0][\"slots\"]\n",
    "        turn[\"slots\"] = turn[\"slots\"].copy()  # shallow copy #1: don't override the config\n",
    "        # fill missing slots using defaults\n",
    "        for slot, val in default_slots.items():\n",
    "            if turn[\"slots\"].get(slot) is None:\n",
    "                turn[\"slots\"][slot] = val\n",
    "\n",
    "decoder_input_ids = (\n",
    "    canary.prompt.encode_dialog(turns=turns)[\"context_ids\"]\n",
    "    .unsqueeze(0)\n",
    "    .repeat(len(audio_batch), 1)\n",
    "    .to(\"cpu\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e66f8b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.inference_mode():\n",
    "    _, encoded_len, encoded, encoded_mask = canary(input_signal=audios, input_signal_length=lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "84519519",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(encoded, \"encoded8.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6953af43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2026-01-08 00:21:36 nemo_logging:393] Changed decoding strategy to \n",
      "    strategy: greedy\n",
      "    compute_hypothesis_token_set: false\n",
      "    preserve_alignments: null\n",
      "    confidence_cfg:\n",
      "      preserve_frame_confidence: false\n",
      "      preserve_token_confidence: false\n",
      "      preserve_word_confidence: false\n",
      "      exclude_blank: true\n",
      "      aggregation: min\n",
      "      tdt_include_duration: false\n",
      "      method_cfg:\n",
      "        name: entropy\n",
      "        entropy_type: tsallis\n",
      "        alpha: 0.33\n",
      "        entropy_norm: exp\n",
      "        temperature: DEPRECATED\n",
      "    compute_langs: false\n",
      "    greedy:\n",
      "      temperature: null\n",
      "      max_generation_delta: -1\n",
      "      preserve_alignments: false\n",
      "      preserve_token_confidence: false\n",
      "      confidence_method_cfg:\n",
      "        name: entropy\n",
      "        entropy_type: tsallis\n",
      "        alpha: 0.33\n",
      "        entropy_norm: exp\n",
      "        temperature: DEPRECATED\n",
      "      n_samples: 1\n",
      "    beam:\n",
      "      beam_size: 1\n",
      "      search_type: default\n",
      "      len_pen: 1.0\n",
      "      max_generation_delta: -1\n",
      "      return_best_hypothesis: true\n",
      "      preserve_alignments: false\n",
      "      ngram_lm_model: null\n",
      "      ngram_lm_alpha: 0.0\n",
      "      boosting_tree:\n",
      "        model_path: null\n",
      "        key_phrases_file: null\n",
      "        key_phrases_list: null\n",
      "        context_score: 1.0\n",
      "        depth_scaling: 1.0\n",
      "        unk_score: 0.0\n",
      "        final_eos_score: 1.0\n",
      "        score_per_phrase: 0.0\n",
      "        source_lang: en\n",
      "        use_triton: true\n",
      "        uniform_weights: false\n",
      "        use_bpe_dropout: false\n",
      "        num_of_transcriptions: 5\n",
      "        bpe_alpha: 0.3\n",
      "      boosting_tree_alpha: 0.0\n",
      "    temperature: 1.0\n",
      "    return_best_hypothesis: true\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "canary.change_decoding_strategy({\"strategy\":\"greedy\", \"return_best_hypothesis\":True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8895a52f",
   "metadata": {},
   "outputs": [],
   "source": [
    "hypothesis, = canary.decoding.decoding(encoder_hidden_states=encoded, encoder_input_mask = encoded_mask, decoder_input_ids=decoder_input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7dceedd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Hypothesis(score=0.0, y_sequence=tensor([2215, 2359, 2505, 2218, 2552, 2212, 2529, 2178, 2609, 2728, 2390, 2212,\n",
       "         2184, 2267, 2255, 2204, 2474, 2178, 2243, 2200, 2218, 2403, 2205, 2351,\n",
       "         2440, 2184, 2459, 2866, 3062, 2327, 2611, 2197, 2955, 2400, 3054, 2218,\n",
       "         2389, 2247, 2285, 2242, 2352, 2529, 2177, 2335, 2270, 2348, 2194, 2474,\n",
       "         2763, 2228, 2299, 2290, 3075, 2223, 3051, 2412, 2213]), text=' Sadik , Der in ihren Herzen wie in seinem eigenen las , hatte immer seine Freude daran gehabt , dem Wachstum ihrer gegenseitigen Neigung zuzusehen .', dec_out=None, dec_state=None, timestamp=[], alignments=None, frame_confidence=None, token_confidence=None, word_confidence=None, length=0, y=None, lm_state=None, lm_scores=None, ngram_lm_state=None, tokens=None, last_token=None, token_duration=None, last_frame=None),\n",
       " Hypothesis(score=0.0, y_sequence=tensor([2284, 2267, 2275, 2222, 2296, 2308, 2291, 2629, 2178, 2232, 2256, 2267,\n",
       "         2965, 2194, 2262, 2213, 2569, 2247, 2407, 2218, 2239, 3051, 2257, 3052,\n",
       "         3075, 2681, 3057, 2687, 3079, 2205, 2351, 2519, 3069, 2237, 2281, 2213]), text=' Kein Falsch ist an ihnen und kein Flitter . Ein Wort , eine Enziansblüte im Gebirge .', dec_out=None, dec_state=None, timestamp=[], alignments=None, frame_confidence=None, token_confidence=None, word_confidence=None, length=0, y=None, lm_state=None, lm_scores=None, ngram_lm_state=None, tokens=None, last_token=None, token_duration=None, last_frame=None),\n",
       " Hypothesis(score=0.0, y_sequence=tensor([2337, 2301, 3075, 2228, 2473, 2604, 2374, 2366, 2193, 2263, 3060, 2275,\n",
       "         2177, 3060, 2181, 2307, 2258, 2326, 2177, 3068, 2303, 2287, 2184, 2267,\n",
       "         2287, 2242, 2188, 2250, 2385, 3068, 2239, 2256, 2868, 2188, 2250, 2385,\n",
       "         2268, 2219, 2198, 2205, 3068, 2329, 3092, 2446, 2251, 2289, 2205, 3070]), text=' Vierzig Jahre war Conrad Ferdinand Mayer, als er sein erstes Buch, ein kleines Buch Gedichte, veröffentlichte.', dec_out=None, dec_state=None, timestamp=[], alignments=None, frame_confidence=None, token_confidence=None, word_confidence=None, length=0, y=None, lm_state=None, lm_scores=None, ngram_lm_state=None, tokens=None, last_token=None, token_duration=None, last_frame=None),\n",
       " Hypothesis(score=0.0, y_sequence=tensor([2241, 2260, 3035, 2539, 2289, 2184, 2362, 2218, 2256, 2267, 2178, 2229,\n",
       "         2841, 2907, 2411, 2281, 2282, 2290, 2256, 2387, 2178, 2303, 2241, 2316,\n",
       "         2196, 2238, 2213]), text=' die so glücklich sind , keinen anderen Gesetzgeber zu kennen als die Natur .', dec_out=None, dec_state=None, timestamp=[], alignments=None, frame_confidence=None, token_confidence=None, word_confidence=None, length=0, y=None, lm_state=None, lm_scores=None, ngram_lm_state=None, tokens=None, last_token=None, token_duration=None, last_frame=None),\n",
       " Hypothesis(score=0.0, y_sequence=tensor([2930, 2185, 2434, 2272, 2338, 2195, 2285, 2178, 2218, 2185, 2387, 2287,\n",
       "         2529, 2177, 2594, 3053, 2211, 2320, 2183, 2610, 2360, 2184, 2198, 2202,\n",
       "         3082, 2452, 3051, 2747, 2447, 2942, 2327, 2353, 2351, 2440, 2260, 2291,\n",
       "         2711, 2281, 2412, 2185, 2189, 2425, 2218, 2259, 3057, 2287, 2538, 2257,\n",
       "         2187, 3051, 2297, 2482, 2244, 3058, 2437, 2205, 2213]), text=' Was wollten wir machen , wenn er ihrer zwei oder drei mit sich nähme ? Er würde es immer so anzugehen wissen , dass er am Ende recht behielte .', dec_out=None, dec_state=None, timestamp=[], alignments=None, frame_confidence=None, token_confidence=None, word_confidence=None, length=0, y=None, lm_state=None, lm_scores=None, ngram_lm_state=None, tokens=None, last_token=None, token_duration=None, last_frame=None),\n",
       " Hypothesis(score=0.0, y_sequence=tensor([2930, 2308, 2360, 2258, 2189, 2262, 2319, 2656, 2188, 2262, 2693, 2431,\n",
       "         2412, 2747, 2927, 2335, 2361, 2353, 2675, 2747, 2961, 2308, 2287]), text=' Was ist mit Mister Rochester geschehen ? Wie geht es ihm ? Wo ist er', dec_out=None, dec_state=None, timestamp=[], alignments=None, frame_confidence=None, token_confidence=None, word_confidence=None, length=0, y=None, lm_state=None, lm_scores=None, ngram_lm_state=None, tokens=None, last_token=None, token_duration=None, last_frame=None),\n",
       " Hypothesis(score=0.0, y_sequence=tensor([2234, 2298, 2202, 3082, 2442, 2205, 2287, 2184, 2198, 2389, 2275, 3051,\n",
       "         3062, 2177, 2213, 2608, 2374, 2239, 2190, 2462, 2188, 2397, 2539, 2600,\n",
       "         2787, 2190, 2301, 2442, 2290, 3033, 2197, 2270, 2213, 2463, 2256, 2298,\n",
       "         2314, 2443, 2329, 3057, 2198, 2406, 2213]), text=' Dann näherte er sich dem Feuer . Es war ein hartes Stück Arbeit hierher zu gelangen . Das kann ich Sie versichern .', dec_out=None, dec_state=None, timestamp=[], alignments=None, frame_confidence=None, token_confidence=None, word_confidence=None, length=0, y=None, lm_state=None, lm_scores=None, ngram_lm_state=None, tokens=None, last_token=None, token_duration=None, last_frame=None),\n",
       " Hypothesis(score=0.0, y_sequence=tensor([2473, 2213, 2927, 2320, 2352, 2521, 2242, 2307, 2239, 3051, 2293, 2547,\n",
       "         2213, 2430, 2331, 2276, 2349, 3061, 2625, 2182, 2482, 2391, 3061, 3082,\n",
       "         2281, 2213]), text=' Ja . Wiederum entstand eine Pause . Die Uhr schlug acht Schläge .', dec_out=None, dec_state=None, timestamp=[], alignments=None, frame_confidence=None, token_confidence=None, word_confidence=None, length=0, y=None, lm_state=None, lm_scores=None, ngram_lm_state=None, tokens=None, last_token=None, token_duration=None, last_frame=None)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "canary.decoding.decode_hypothesis(hypothesis)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc4b5a36",
   "metadata": {},
   "source": [
    "## Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2c239c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from export import exportable_forward, stft\n",
    "import types\n",
    "\n",
    "\n",
    "canary.preprocessor.featurizer.forward = types.MethodType(exportable_forward, canary.preprocessor.featurizer)\n",
    "canary.preprocessor.featurizer.stft = types.MethodType(stft, canary.preprocessor.featurizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b0d069c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2026-01-08 00:21:41 nemo_logging:393] Successfully exported AudioToMelSpectrogramPreprocessor to canary/preprocessor.onnx\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(['canary/preprocessor.onnx'],\n",
       " ['nemo.collections.asr.modules.audio_preprocessing.AudioToMelSpectrogramPreprocessor exported to ExportFormat.ONNX'])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "canary.preprocessor.export(\n",
    "    \"canary/preprocessor.onnx\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fb15753b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2026-01-08 00:21:45 nemo_logging:393] Successfully exported ConformerEncoder to canary/encoder.onnx\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(['canary/encoder.onnx'],\n",
       " ['nemo.collections.asr.modules.conformer_encoder.ConformerEncoder exported to ExportFormat.ONNX'])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "canary.encoder.export(\"canary/encoder.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "29aa586a",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size, seq_len, _ = canary.encoder.input_example()[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4ae75b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "example_input = torch.randn(batch_size, seq_len, 512)\n",
    "dynamic_axes = {\"encoder_output\": {0: \"batch_size\", 1: \"seq_len\"}}\n",
    "torch.onnx.export(\n",
    "    canary.encoder_decoder_proj,\n",
    "    (example_input,),\n",
    "    \"canary/encoder_decoder_proj.onnx\",\n",
    "    dynamic_axes=dynamic_axes,\n",
    "    input_names = [\"encoder_output\"],\n",
    "    output_names = [\"proj_output\"],\n",
    "    opset_version=17\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d9db359",
   "metadata": {},
   "source": [
    "# Decoder Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b4093225",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded = torch.load(\"encoded8.pt\", weights_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e31efaf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 129, 1024])\n"
     ]
    }
   ],
   "source": [
    "print(encoded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e5b37f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import types\n",
    "def _exportable_get_memory_states(self, decoder_states, decoder_mems, i=0):\n",
    "        # Access memory for the i-th layer\n",
    "        past_mem = decoder_mems[i]\n",
    "        # Concatenate memory and current states.\n",
    "        # torch.cat handles empty tensors (seq_len=0) correctly in PyTorch/ONNX.\n",
    "        return torch.cat((past_mem, decoder_states), dim=1)\n",
    "\n",
    "canary.transf_decoder.decoder._get_memory_states = types.MethodType(_exportable_get_memory_states, canary.transf_decoder.decoder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "094ff560",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nemo.collections.common.parts.transformer_utils import form_attention_mask\n",
    "\n",
    "def exportable_forward(\n",
    "    self,\n",
    "    decoder_states,\n",
    "    decoder_mask,\n",
    "    encoder_states,\n",
    "    encoder_mask,\n",
    "    decoder_mems,\n",
    "):\n",
    "    # 1. Create masks\n",
    "    # Ensure form_attention_mask uses torch operations (no numpy/python loops)\n",
    "    decoder_attn_mask = form_attention_mask(decoder_mask, diagonal=self.diagonal)\n",
    "    encoder_attn_mask = form_attention_mask(encoder_mask)\n",
    "\n",
    "    # 2. Process layers\n",
    "    new_mems = []\n",
    "\n",
    "    # Layer 0: Embedding memory\n",
    "    memory_states = self._get_memory_states(decoder_states, decoder_mems, 0)\n",
    "    new_mems.append(memory_states.unsqueeze(0))\n",
    "\n",
    "    curr_states = decoder_states\n",
    "    for i, layer in enumerate(self.layers):\n",
    "        # print(f\"curr_states: {curr_states[:2,:2,:2]}\")\n",
    "        # print(f\"decoder_attn_mask: {decoder_attn_mask[:2,:2,:2]}\")\n",
    "        # print(f\"memory_states: {memory_states[:2,:2,:2]}\")\n",
    "        # print(memory_states.shape)\n",
    "\n",
    "        curr_states = layer(curr_states, decoder_attn_mask, memory_states, encoder_states, encoder_attn_mask)\n",
    "        # print(f\"curr_states: {curr_states[:2,:2,:2]}\")\n",
    "        # print(f\"curr_states shape: {curr_states.shape}\")\n",
    "        # Memory for layer i+1\n",
    "        memory_states = self._get_memory_states(curr_states, decoder_mems, i + 1)\n",
    "        new_mems.append(memory_states.unsqueeze(0))\n",
    "\n",
    "    if self.final_layer_norm is not None:\n",
    "        curr_states = self.final_layer_norm(curr_states)\n",
    "        memory_states = self._get_memory_states(curr_states, decoder_mems, len(self.layers) + 1)\n",
    "        new_mems.append(memory_states.unsqueeze(0))\n",
    "\n",
    "    # Concatenate all memories into one tensor for the output\n",
    "    # Shape: [6, B, L_total, H]\n",
    "    combined_mems = torch.cat(new_mems,dim=0)\n",
    "    return combined_mems\n",
    "\n",
    "\n",
    "canary.transf_decoder.decoder.forward = types.MethodType(exportable_forward, canary.transf_decoder.decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dbdb12a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerDecoderWrapper(torch.nn.Module):\n",
    "    def __init__(self, canary):\n",
    "        super().__init__()\n",
    "        self.decoder = canary.transf_decoder.decoder\n",
    "        self.embedding = canary.transf_decoder.embedding\n",
    "        self.num_states = canary.transf_decoder.num_states\n",
    "        self.token_classifier = canary.decoding.log_softmax_module\n",
    "    def forward(self,\n",
    "    input_ids,      # [B, CurrSeqLen]\n",
    "    decoder_mask,   # [B, TotalSeqLen]\n",
    "    encoder_embeddings,\n",
    "    encoder_mask,\n",
    "    decoder_mems,   # [num_states, B, MemLen, H]\n",
    "    start_pos,      # scalar tensor\n",
    "    ):\n",
    "        # Pass start_pos as a tensor to avoid it being optimized away as a constant\n",
    "        decoder_embeddings = self.embedding.forward(input_ids=input_ids, start_pos=start_pos)\n",
    "        # Decode\n",
    "        combined_mems = self.decoder(\n",
    "            decoder_states=decoder_embeddings,\n",
    "            decoder_mask=decoder_mask,\n",
    "            encoder_states=encoder_embeddings,\n",
    "            encoder_mask=encoder_mask,\n",
    "            decoder_mems=decoder_mems,\n",
    "        )\n",
    "        with self.token_classifier.with_log_softmax_enabled(False) as clf:\n",
    "            logits = clf(hidden_states = combined_mems[-1][:, -1:])\n",
    "        return logits, combined_mems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a9a40c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "wrapper = TransformerDecoderWrapper(canary).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "724bfa4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_sequence = []\n",
    "input_ids = decoder_input_ids.clone()\n",
    "memories = torch.zeros((6, len(audio_batch), 0, 1024))\n",
    "pad_id = 2\n",
    "eos_id = 3\n",
    "pad_profile = torch.zeros(len(audio_batch),1) # which batched elements are already finished\n",
    "\n",
    "with torch.inference_mode():\n",
    "    for i in range(80):\n",
    "        decoder_mask = (input_ids != pad_id).float()\n",
    "        logits, memories = wrapper(input_ids= input_ids, decoder_mask=decoder_mask, encoder_embeddings=encoded, encoder_mask = encoded_mask, decoder_mems = memories, start_pos = torch.tensor(i))\n",
    "        input_ids = logits[:,-1].argmax(dim=-1, keepdim=True)\n",
    "\n",
    "        eos_reached = (input_ids == eos_id)\n",
    "        pad_profile[eos_reached.squeeze(-1)] = 1\n",
    "        if pad_profile.sum() == len(audio_batch):\n",
    "            break\n",
    "        decoded_sequence.append(input_ids)\n",
    "sequences = torch.hstack(decoded_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "42427167",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Sadik, Der in ihren Herzen wie in seinem eigenen las, hatte immer seine Freude daran gehabt, dem Wachstum ihrer gegenseitigen Neigung zuzusehen.\n",
      " Kein Falsch ist an ihnen und kein Flitter. Ein Wort, eine Enziansblüte im Gebirge.\n",
      " Vierzig Jahre war Conrad Ferdinand Mayer, als er sein erstes Buch, ein kleines Buch Gedichte, veröffentlichte.\n",
      " die so glücklich sind, keinen anderen Gesetzgeber zu kennen als die Natur.\n",
      " Was wollten wir machen, wenn er ihrer zwei oder drei mit sich nähme? Er würde es immer so anzugehen wissen, dass er am Ende recht behielte.\n",
      " Was ist mit Mister Rochester geschehen? Wie geht es ihm? Wo ist er\n",
      " Dann näherte er sich dem Feuer. Es war ein hartes Stück Arbeit hierher zu gelangen. Das kann ich Sie versichern.\n",
      " Ja. Wiederum entstand eine Pause. Die Uhr schlug acht Schläge.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "for sequence in sequences:\n",
    "    text_tokens = []\n",
    "    for t in sequence:\n",
    "        if t.item() == eos_id:\n",
    "            break\n",
    "        text_tokens.append(t.item())\n",
    "    text = canary.tokenizer.ids_to_text(text_tokens)\n",
    "    # we always have space before punctuation, remove it\n",
    "    text = re.sub(r'\\s([?.!,\"](?:\\s|$))', r'\\1', text)\n",
    "    print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9e414f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_decoder_to_onnx(model, onnx_path):\n",
    "    batch_size = 1\n",
    "    enc_seq_len = 10\n",
    "    num_states = 6\n",
    "    hidden_dim = 1024\n",
    "\n",
    "    # Dummy inputs\n",
    "    input_ids = torch.ones((batch_size, 1), dtype=torch.long)\n",
    "    decoder_mask = torch.ones((batch_size, 1), dtype=torch.float32)\n",
    "    encoder_embeddings = torch.randn((batch_size, enc_seq_len, hidden_dim))\n",
    "    encoder_mask = torch.ones((batch_size, enc_seq_len), dtype=torch.float32)\n",
    "    # Use sequence length 1 instead of 0 for dummy inputs to ensure graph logic is traced\n",
    "    decoder_mems = torch.zeros((num_states, batch_size, 1, hidden_dim))\n",
    "    start_pos = torch.tensor(0, dtype=torch.long)\n",
    "\n",
    "    dynamic_axes = {\n",
    "        \"input_ids\": {0: \"batch_size\", 1: \"seq_len\"},\n",
    "        \"decoder_mask\": {0: \"batch_size\", 1: \"total_seq_len\"},\n",
    "        \"encoder_embeddings\": {0: \"batch_size\", 1: \"enc_seq_len\"},\n",
    "        \"encoder_mask\": {0: \"batch_size\", 1: \"enc_seq_len\"},\n",
    "        \"decoder_mems\": {1: \"batch_size\", 2: \"mem_len\"},\n",
    "        \"logits\": {0: \"batch_size\"},\n",
    "        \"new_mems\": {1: \"batch_size\", 2: \"total_seq_len\"},\n",
    "    }\n",
    "\n",
    "    torch.onnx.export(\n",
    "        model,\n",
    "        (input_ids, decoder_mask, encoder_embeddings, encoder_mask, decoder_mems, start_pos),\n",
    "        onnx_path,\n",
    "        export_params=True,\n",
    "        opset_version=17,\n",
    "        do_constant_folding=True,\n",
    "        input_names=[\"input_ids\", \"decoder_mask\", \"encoder_embeddings\", \"encoder_mask\", \"decoder_mems\", \"start_pos\"],\n",
    "        output_names=[\"logits\", \"new_mems\"],\n",
    "        dynamic_axes=dynamic_axes,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "849e2c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "export_decoder_to_onnx(wrapper, \"canary/decoder.onnx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "103b5c0d",
   "metadata": {},
   "source": [
    "# ONNX inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "48c9f953",
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnxruntime as ort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3dd398c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_session = ort.InferenceSession(\"canary/encoder.onnx\")\n",
    "preprocessor_session = ort.InferenceSession(\"canary/preprocessor.onnx\")\n",
    "proj_session = ort.InferenceSession(\"canary/encoder_decoder_proj.onnx\")\n",
    "decoder_session = ort.InferenceSession(\"canary/decoder.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "413bcc74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "\n",
    "audio, sr = librosa.load(\"test_audio.wav\", sr=16000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ff30eb92",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_np, length_np = preprocessor_session.run(None, {\"input_signal\": audio.astype(np.float32).reshape(1, -1), \"length\": np.array([len(audio)], dtype=np.int64)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d404eb17",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_np, encoded_length_np = encoder_session.run(None, {\"audio_signal\": preprocessed_np, \"length\": length_np})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5e11204a",
   "metadata": {},
   "outputs": [],
   "source": [
    "projected, = proj_session.run(None, {\"encoder_output\": encoded_np.transpose(0,2,1)})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f64d515f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 138, 1024)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "projected.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0d8a63e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a mask using the encoded_length_np tensor that has shape like projected at [0,1]\n",
    "encoded_mask_np = np.arange(encoded_np.shape[2])[None, :] < encoded_length_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "cb35bf45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Es war in den siebziger Jahren an einem Dezember , also am Tage nach Sankt Nikolaus .\n",
      " Es war in den siebziger Jahren an einem Dezember , also am Tage nach Sankt Nikolaus .\n",
      " Es war in den siebziger Jahren an einem Dezember , also am Tage nach Sankt Nikolaus .\n",
      " Es war in den siebziger Jahren an einem Dezember , also am Tage nach Sankt Nikolaus .\n",
      " Es war in den siebziger Jahren an einem Dezember , also am Tage nach Sankt Nikolaus .\n",
      " Es war in den siebziger Jahren an einem Dezember , also am Tage nach Sankt Nikolaus .\n",
      " Es war in den siebziger Jahren an einem Dezember , also am Tage nach Sankt Nikolaus .\n",
      " Es war in den siebziger Jahren an einem Dezember , also am Tage nach Sankt Nikolaus .\n"
     ]
    }
   ],
   "source": [
    "# Decoder Loop\n",
    "input_ids = decoder_input_ids.numpy()\n",
    "memories = np.zeros((6, input_ids.shape[0], 0, 1024), dtype=np.float32)\n",
    "pad_id, eos_id = 2, 3\n",
    "decoded_tokens = []\n",
    "finished = np.zeros(input_ids.shape[0], dtype=bool)\n",
    "\n",
    "for i in range(80):\n",
    "    # decoder_mask is only for the CURRENT token being processed, not the full history\n",
    "    # The memory mechanism handles the historical context\n",
    "    current_decoder_mask = (input_ids != pad_id).astype(np.float32)\n",
    "\n",
    "    outputs = decoder_session.run(None, {\n",
    "        \"input_ids\": input_ids.astype(np.int64),\n",
    "        \"decoder_mask\": current_decoder_mask,\n",
    "        \"encoder_embeddings\": projected,\n",
    "        \"encoder_mask\": encoded_mask_np.astype(np.float32),\n",
    "        \"decoder_mems\": memories,\n",
    "        \"start_pos\": np.array(i, dtype=np.int64)\n",
    "    })\n",
    "    logits, memories = outputs[0], outputs[1]\n",
    "\n",
    "    # Greedy selection\n",
    "    next_tokens = np.argmax(logits[:, -1, :], axis=-1, keepdims=True)\n",
    "    input_ids = next_tokens\n",
    "\n",
    "    finished |= (next_tokens.flatten() == eos_id)\n",
    "    if finished.all():\n",
    "        break\n",
    "    decoded_tokens.append(next_tokens)\n",
    "\n",
    "result_ids = np.concatenate(decoded_tokens, axis=1)\n",
    "for res in result_ids:\n",
    "    print(canary.tokenizer.ids_to_text(res[res != eos_id].tolist()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
